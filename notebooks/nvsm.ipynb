{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NVSM(nn.Module):\n",
    "    def __init__(self, n_doc, n_tok, dim_doc_emb, dim_tok_emb, neg_sampling_rate, \n",
    "                 pad_token_id):\n",
    "        super(NVSM, self).__init__()\n",
    "        self.doc_emb           = nn.Embedding(n_doc, embedding_dim = dim_doc_emb)\n",
    "        self.tok_emb           = nn.Embedding(n_tok, embedding_dim = dim_tok_emb)\n",
    "        self.tok_to_doc        = nn.Linear(dim_tok_emb, dim_doc_emb)\n",
    "        self.bias              = nn.Parameter(torch.Tensor(dim_doc_emb))\n",
    "        self.neg_sampling_rate = neg_sampling_rate\n",
    "        self.pad_token_id      = pad_token_id\n",
    "        \n",
    "    def query_to_tensor(self, query):\n",
    "        '''\n",
    "        Computes the average of the word embeddings of the query. This method \n",
    "        corresponds to the function 'g' in the article.\n",
    "        '''\n",
    "        # Create a mask to ignore padding embeddings\n",
    "        query_mask    = (query != self.pad_token_id).float()\n",
    "        # Compute the number of tokens in each query to properly compute the \n",
    "        # average\n",
    "        tok_by_input  = query_mask.sum(dim = 1)\n",
    "        query_tok_emb = self.tok_emb(query)\n",
    "        query_tok_emb = query_tok_emb * query_mask.unsqueeze(-1)\n",
    "        # Compute the average of the embeddings\n",
    "        query_emb     = query_tok_emb.sum(dim = 1) / tok_by_input.unsqueeze(-1)\n",
    "        \n",
    "        return query_emb\n",
    "    \n",
    "    def normalize_query_tensor(self, query_tensor):\n",
    "        '''\n",
    "        Divides each query tensor by its L2 norm. This method corresponds to \n",
    "        the function 'norm' in the article.\n",
    "        '''\n",
    "        norm = torch.norm(query_tensor, dim = 1) # we might have to detach this value \n",
    "                                                 # from the computation graph.\n",
    "        return query_tensor / norm.unsqueeze(-1)\n",
    "        \n",
    "    def query_to_doc_space(self, query):\n",
    "        '''\n",
    "        Projects a query vector into the document vector space. This method corresponds \n",
    "        to the function 'f' in the article.\n",
    "        '''\n",
    "        return self.tok_to_doc(query)\n",
    "    \n",
    "    def score(self, query, document):\n",
    "        '''\n",
    "        Computes the cosine similarity between a query and a document embedding.\n",
    "        This method corresponds to the function 'score' in the article.\n",
    "        '''\n",
    "        # batch dot product using batch matrix multiplication\n",
    "        num   = torch.bmm(query.unsqueeze(1), document.unsqueeze(-1))\n",
    "        denum = torch.norm(query, dim = 1) * torch.norm(document, dim = 1)\n",
    "        \n",
    "        return num / denum\n",
    "        \n",
    "    def non_stand_projection(self, n_gram):\n",
    "        '''\n",
    "        Computes the non-standard projection of a n-gram into the document vector \n",
    "        space. This method corresponds to the function 'T^~' in the article.\n",
    "        '''\n",
    "        n_gram_tensor      = self.query_to_tensor(n_gram)\n",
    "        norm_n_gram_tensor = self.normalize_query_tensor(n_gram_tensor)\n",
    "        projection         = self.query_to_doc_space(norm_n_gram_tensor)\n",
    "        \n",
    "        return projection\n",
    "    \n",
    "    def _custom_batchnorm(self, batch):\n",
    "        '''\n",
    "        Computes the variant of the batch normalization formula used in this article. \n",
    "        It only uses a bias and no weights.\n",
    "        '''\n",
    "        batch_feat_norm = (batch - batch.mean(dim = 0)) / batch.std(dim = 0)\n",
    "        batch_feat_norm = batch_feat_norm + self.bias\n",
    "        \n",
    "        return batch_feat_norm\n",
    "    \n",
    "    def stand_projection(self, batch):\n",
    "        '''\n",
    "        Computes the standard projection of a n-gram into document vector space with\n",
    "        a hardtanh activation. This method corresponds to the function 'T' in the \n",
    "        article.\n",
    "        '''\n",
    "        non_stand_proj = self.non_stand_projection(batch) \n",
    "        bn             = self._custom_batchnorm(non_stand_proj)\n",
    "        activation     = F.hardtanh(bn)\n",
    "\n",
    "        return activation\n",
    "    \n",
    "    def representation_similarity(self, query, document):\n",
    "        '''\n",
    "        Computes the similarity between a query and a document. This method corresponds \n",
    "        to the function 'P' in the article.\n",
    "        '''\n",
    "        document_emb  = self.doc_emb(document)\n",
    "        query_proj    = self.stand_projection(query)\n",
    "        # If we have a single document to match against each query, we have\n",
    "        # to reshape the tensor to compute a simple dot product.\n",
    "        # Otherwise, we compute a simple matrix multiplication to match the \n",
    "        # query against each document.\n",
    "        if len(document_emb.shape) == 2:\n",
    "            document_emb = document_emb.unsqueeze(1)\n",
    "        dot_product   = torch.bmm(document_emb, query_proj.unsqueeze(-1))\n",
    "        similarity    = torch.sigmoid(dot_product)\n",
    "        \n",
    "        return similarity.squeeze()\n",
    "    \n",
    "    def forward(self, query, document):\n",
    "        '''\n",
    "        Approximates the probability of document given query by uniformly sampling \n",
    "        constrastive examples. This method corresponds to the 'P^~' function in the \n",
    "        article.\n",
    "        '''\n",
    "        # Positive term, this should be maximized as it indicates how similar the\n",
    "        # correct document is to the query\n",
    "        pos_repr = self.representation_similarity(query, document)\n",
    "        \n",
    "        # Sampling uniformly 'self.neg_sampling_rate' documents to compute the \n",
    "        # negative term. We first randomly draw the indices of the documents and \n",
    "        # then we compute the similarity with the query.\n",
    "        z               = self.neg_sampling_rate # corresponds to the z variable in \n",
    "                                                 # the article\n",
    "        n_docs          = self.doc_emb.num_embeddings\n",
    "        neg_sample_size = (query.size(0), z)\n",
    "        neg_sample      = torch.randint(low = 0, high = n_docs, size = neg_sample_size)\n",
    "        neg_repr        = self.representation_similarity(query, neg_sample)\n",
    "        \n",
    "        # Probability computation\n",
    "        positive_term = torch.log(pos_repr)\n",
    "        negative_term = torch.log(1 - neg_repr).sum(dim = 1)\n",
    "        proba         = ((z + 1) / (2 * z)) * (z * positive_term + negative_term)\n",
    "        \n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(nvsm, pred, lamb):\n",
    "    output_term = pred.mean()\n",
    "    sum_square  = lambda m: (m.weight * m.weight).sum()\n",
    "    reg_term    = sum_square(nvsm.tok_emb) + \\\n",
    "                  sum_square(nvsm.doc_emb) + \\\n",
    "                  sum_square(nvsm.tok_to_doc)\n",
    "    loss        = -output_term + (lamb / (2 * pred.shape[0])) * reg_term\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvsm = NVSM(\n",
    "    n_doc             = 20, \n",
    "    n_tok             = 9, \n",
    "    dim_doc_emb       = 10, \n",
    "    dim_tok_emb       = 7,\n",
    "    neg_sampling_rate = 4,\n",
    "    pad_token_id      = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 0, 0],\n",
      "        [4, 5, 6, 7, 8],\n",
      "        [2, 7, 8, 3, 0]])\n",
      "tensor([2, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "query = torch.tensor([\n",
    "    [1, 2, 3, 0, 0], \n",
    "    [4, 5, 6, 7, 8],\n",
    "    [2, 7, 8, 3, 0]\n",
    "])\n",
    "document = torch.tensor([2,3,7])\n",
    "print(query)\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(nvsm.parameters())\n",
    "lamb      = 1e-3 # loss param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1081, -0.9414, -0.4933], grad_fn=<MulBackward0>)\n",
      "Step [0]: 0.8936313986778259\n",
      "tensor([-1.4402, -1.1482, -0.9024], grad_fn=<MulBackward0>)\n",
      "tensor([-1.6287, -0.9938, -0.9824], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1443, -1.1805, -1.0564], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9780, -0.9915, -2.7128], grad_fn=<MulBackward0>)\n",
      "tensor([-1.6149, -0.8155, -2.8458], grad_fn=<MulBackward0>)\n",
      "tensor([-4.3398, -0.9959, -1.4829], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3988, -0.6374, -1.5953], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8421, -1.1334, -0.5179], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7523, -0.8752, -1.0067], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5526, -0.8442, -1.8128], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4434, -0.5478, -1.3667], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2912, -0.9451, -1.3938], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6381, -1.0007, -1.4729], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2193, -1.1772, -1.4653], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6403, -0.9797, -0.9533], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4828, -0.5751, -1.9639], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2715, -1.2876, -0.6928], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0864, -0.9298, -1.0892], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9493, -1.3509, -1.0231], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3014, -1.5315, -0.7571], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9258, -4.6549, -0.8056], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3791, -3.4031, -0.9949], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5276, -0.8810, -2.8756], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0944, -2.7511, -1.5300], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3749, -0.7609, -1.0521], grad_fn=<MulBackward0>)\n",
      "Step [25]: 1.1087062358856201\n",
      "tensor([-2.2946, -1.3458, -1.5519], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5683, -0.4947, -1.0876], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1472, -1.3906, -1.1632], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0537, -2.4816, -1.6704], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6909, -0.7732, -0.4973], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3319, -0.8989, -3.4520], grad_fn=<MulBackward0>)\n",
      "tensor([-4.5687, -0.7951, -2.5151], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8385, -0.4508, -0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4183, -0.8382, -2.6678], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7657, -1.1020, -1.6882], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7802, -0.6618, -1.3031], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2445, -2.7089, -1.1423], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6923, -2.6834, -0.9922], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8945, -2.5877, -1.1772], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8929, -0.9564, -2.7746], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3978, -1.1706, -1.4395], grad_fn=<MulBackward0>)\n",
      "tensor([-4.2555, -0.6044, -2.8302], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4684, -0.5167, -1.0145], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3372, -0.7790, -1.8508], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7113, -1.3932, -2.5929], grad_fn=<MulBackward0>)\n",
      "tensor([-1.8502, -0.4571, -0.8434], grad_fn=<MulBackward0>)\n",
      "tensor([-4.1745, -0.6915, -0.9132], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3978, -2.1063, -1.0698], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8664, -2.6031, -1.3862], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7552, -1.0326, -1.3999], grad_fn=<MulBackward0>)\n",
      "Step [50]: 1.1086620092391968\n",
      "tensor([-1.2674, -1.1469, -2.8012], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2073, -1.4467, -1.2690], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6308, -2.4930, -0.9089], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8313, -3.0838, -1.0203], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4619, -2.4424, -1.1176], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3459, -4.5530, -1.0607], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0679, -1.2808, -0.5477], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4415, -2.7852, -1.5503], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2401, -1.1297, -1.0077], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3537, -2.4558, -1.0495], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2621, -1.1878, -0.6300], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3220, -2.6854, -1.8926], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7811, -0.8703, -2.9294], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1509, -1.0900, -2.5006], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0866, -0.9573, -1.5263], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0627, -0.8746, -0.6732], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0346, -0.7002, -1.2809], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3465, -0.7446, -0.8745], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2614, -2.7665, -0.7339], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0585, -0.9308, -1.0889], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0425, -1.0241, -1.1350], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3580, -1.1516, -1.7668], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4697, -0.5673, -1.5568], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4281, -1.9658, -1.0645], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8334, -1.1642, -2.9734], grad_fn=<MulBackward0>)\n",
      "Step [75]: 1.7031201124191284\n",
      "tensor([-0.9823, -2.6928, -0.9794], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9865, -2.5724, -1.0700], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2379, -0.6055, -1.1036], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9382, -2.7016, -1.2427], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1605, -2.4991, -2.0024], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3130, -0.6979, -1.3424], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6627, -0.9468, -1.3041], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0760, -0.8164, -0.6947], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0842, -1.7552, -1.5927], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6846, -2.4508, -1.4771], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7028, -0.9706, -1.0933], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3413, -0.9820, -0.9363], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7769, -0.9049, -1.4013], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0451, -1.3658, -0.6551], grad_fn=<MulBackward0>)\n",
      "tensor([-3.5119, -0.8974, -1.1923], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7473, -0.7583, -1.0757], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3560, -0.9235, -0.9477], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4445, -0.5530, -0.7740], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6810, -2.4177, -1.0602], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1307, -0.9145, -2.9087], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0256, -0.8435, -1.0996], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3055, -1.0227, -1.2128], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9083, -0.8755, -0.4556], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9426, -0.8096, -1.1943], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0655, -1.4358, -1.1699], grad_fn=<MulBackward0>)\n",
      "Step [100]: 1.269895315170288\n",
      "tensor([-0.9224, -0.7148, -0.8551], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1569, -0.6317, -0.8542], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6437, -1.1901, -0.9324], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7920, -0.8453, -2.8177], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0430, -2.5028, -0.9373], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5970, -0.8014, -1.3534], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0645, -1.3202, -1.8898], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1130, -1.0096, -2.6414], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8354, -2.6226, -3.6611], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5096, -1.0217, -1.3012], grad_fn=<MulBackward0>)\n",
      "tensor([-4.2395, -1.0012, -1.1395], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3001, -1.1646, -0.9217], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5956, -0.4642, -1.4830], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6702, -1.1678, -1.1852], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7347, -1.1534, -1.1314], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1246, -0.8209, -1.1931], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8775, -1.0403, -1.5166], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4185, -0.6931, -0.9938], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6827, -0.6778, -1.3613], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5570, -1.4555, -0.8409], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0584, -0.8719, -1.1089], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9022, -0.7715, -0.8862], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6331, -0.9365, -1.3829], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7724, -0.7033, -2.8228], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9638, -1.2821, -1.2348], grad_fn=<MulBackward0>)\n",
      "Step [125]: 1.2064383029937744\n",
      "tensor([-0.8329, -0.6918, -1.1804], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1431, -0.7466, -0.9189], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9574, -5.0495, -1.5921], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6345, -0.6913, -1.3025], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7825, -1.3380, -0.7343], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7784, -3.1338, -0.9939], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9146, -2.5466, -0.5861], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0433, -0.8128, -1.1095], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9732, -0.4959, -1.3076], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1097, -1.0803, -1.0048], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0629, -0.9810, -0.8125], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4348, -1.3587, -1.6106], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6432, -0.8491, -0.4795], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7842, -0.8185, -1.0835], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1991, -0.7987, -0.8113], grad_fn=<MulBackward0>)\n",
      "tensor([-2.2892, -1.0144, -1.2700], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6261, -1.2208, -1.3644], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4660, -3.2313, -1.1811], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6757, -0.8911, -1.6551], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5264, -2.5734, -1.2895], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4352, -1.0338, -1.1104], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1918, -1.2356, -1.2239], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2195, -2.6399, -1.4555], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4158, -2.5306, -0.6736], grad_fn=<MulBackward0>)\n",
      "tensor([-1.6488, -0.7679, -0.5911], grad_fn=<MulBackward0>)\n",
      "Step [150]: 1.0488847494125366\n",
      "tensor([-0.7962, -2.7847, -0.7579], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3706, -0.9738, -0.9766], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0320, -0.9623, -0.5892], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7314, -0.8731, -2.7239], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0591, -2.5881, -1.1453], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3251, -1.1613, -1.3173], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8474, -0.7050, -2.8268], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0998, -0.9789, -2.4229], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7680, -0.9775, -0.5934], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1879, -1.1025, -0.7389], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7178, -1.3735, -0.9551], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4435, -1.0184, -0.5451], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8805, -0.8929, -2.9450], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8282, -2.2918, -0.6598], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0702, -0.6382, -0.7731], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5774, -1.2874, -0.9501], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8456, -2.3978, -1.4841], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5624, -1.1088, -0.5735], grad_fn=<MulBackward0>)\n",
      "tensor([-2.0569, -0.8721, -2.7278], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7044, -0.9205, -3.1183], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1093, -1.0989, -1.3823], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6071, -0.7688, -0.9556], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5664, -0.8692, -1.6164], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8713, -0.8269, -2.5783], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5604, -2.6509, -0.8684], grad_fn=<MulBackward0>)\n",
      "Step [175]: 1.4062020778656006\n",
      "tensor([-1.0870, -0.6644, -2.7375], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3031, -0.9842, -1.3626], grad_fn=<MulBackward0>)\n",
      "tensor([-4.7497, -1.0323, -1.7227], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7590, -0.6468, -0.9142], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8265, -0.8118, -0.7015], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8814, -1.0370, -1.4695], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0994, -1.1115, -0.5825], grad_fn=<MulBackward0>)\n",
      "tensor([-4.1634, -2.4787, -2.8496], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2620, -1.2582, -0.7853], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4021, -0.8962, -0.7639], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4563, -2.6973, -1.0866], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5780, -2.9203, -0.7246], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7209, -1.3536, -0.9989], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9897, -1.1123, -1.8922], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0532, -0.6651, -1.7377], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0271, -0.6330, -1.0033], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3359, -0.7256, -0.8939], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7573, -0.8874, -0.8949], grad_fn=<MulBackward0>)\n",
      "tensor([-2.9925, -1.0535, -1.3068], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2407, -0.9342, -1.3151], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7831, -0.6665, -1.0358], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6995, -2.6117, -1.1219], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2278, -0.8734, -0.5276], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4423, -1.0450, -1.2752], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9170, -0.7821, -2.7102], grad_fn=<MulBackward0>)\n",
      "Step [200]: 1.5161452293395996\n",
      "tensor([-0.9777, -1.3394, -2.9776], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9921, -0.8344, -1.2255], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8226, -0.9221, -1.1555], grad_fn=<MulBackward0>)\n",
      "tensor([-1.5777, -1.3219, -1.0126], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2660, -0.9570, -0.9516], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4196, -0.8114, -0.6564], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0312, -0.6590, -2.3713], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8582, -2.2657, -1.1764], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7929, -0.6655, -0.5983], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9452, -3.0963, -0.9045], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8863, -0.7952, -0.8362], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6086, -0.9813, -1.1501], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7420, -0.8241, -1.1359], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9898, -0.6384, -1.2601], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9788, -2.6694, -0.9829], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7132, -0.6389, -0.6361], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9310, -2.7019, -1.2355], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4759, -0.6810, -0.8518], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3106, -0.7655, -0.8501], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6024, -2.7445, -1.2516], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0141, -1.2854, -1.1531], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6301, -0.9941, -0.5610], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5734, -1.0844, -0.6875], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8623, -0.7239, -1.1923], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7891, -0.8119, -2.9553], grad_fn=<MulBackward0>)\n",
      "Step [225]: 2.2318367958068848\n",
      "tensor([-0.5402, -0.8813, -0.8839], grad_fn=<MulBackward0>)\n",
      "tensor([-0.3276, -0.6728, -0.9338], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2785, -0.7903, -0.6320], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6352, -0.8966, -0.7325], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8538, -4.2408, -1.0316], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9527, -0.8924, -1.0074], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6428, -2.5853, -1.1683], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7856, -2.8057, -0.9424], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8233, -0.7930, -1.2770], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8400, -0.7364, -2.6646], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6572, -2.4560, -0.7034], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8483, -2.4795, -1.1058], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9780, -0.6837, -1.0294], grad_fn=<MulBackward0>)\n",
      "tensor([-1.9399, -0.9356, -2.4776], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6434, -0.7345, -1.6682], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0101, -0.7060, -0.4808], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4559, -2.6132, -0.8353], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3475, -1.0286, -1.0462], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9689, -0.7771, -0.7911], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8411, -1.1545, -1.2071], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7815, -2.3993, -0.8094], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2100, -0.8406, -0.7381], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0547, -2.4617, -1.0890], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3362, -0.7927, -1.3152], grad_fn=<MulBackward0>)\n",
      "tensor([-3.1920, -0.6419, -2.5408], grad_fn=<MulBackward0>)\n",
      "Step [250]: 2.171355962753296\n",
      "tensor([-1.7355, -0.9095, -0.9605], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6201, -0.8894, -1.2228], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9414, -1.0051, -2.7667], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8999, -0.8458, -2.8488], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6898, -0.8387, -0.9028], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4536, -0.7114, -0.9885], grad_fn=<MulBackward0>)\n",
      "tensor([-3.0127, -0.8635, -0.7558], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8692, -2.3908, -0.9963], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7977, -1.0263, -1.1036], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1288, -2.3025, -1.1703], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1544, -0.7982, -1.3997], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0519, -2.4582, -0.9346], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4723, -1.4168, -1.1925], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7362, -2.5343, -2.4967], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7438, -0.6660, -0.8375], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7791, -0.8744, -1.1465], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6483, -0.8543, -0.7556], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1585, -0.9337, -0.9538], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7117, -1.6517, -0.8128], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7658, -0.9123, -1.3772], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9277, -1.3809, -1.2757], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7080, -0.9272, -0.9564], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6302, -2.4259, -1.0115], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4112, -1.1247, -1.0234], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1687, -0.5776, -1.0264], grad_fn=<MulBackward0>)\n",
      "Step [275]: 0.970737636089325\n",
      "tensor([-1.6053, -2.3177, -0.7937], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0763, -0.9493, -2.6787], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0717, -0.6241, -0.9779], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7441, -0.6843, -0.6676], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7720, -0.7541, -0.5635], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8245, -1.5237, -1.0632], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3591, -1.1304, -0.9155], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5066, -0.5793, -1.3479], grad_fn=<MulBackward0>)\n",
      "tensor([-1.6263, -0.9908, -1.1152], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3215, -0.9428, -0.6966], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1574, -0.8893, -1.6033], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0898, -0.6543, -2.5581], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1161, -0.5008, -0.3930], grad_fn=<MulBackward0>)\n",
      "tensor([-1.7296, -0.6954, -0.9559], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8660, -0.9166, -0.3794], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9466, -0.8760, -0.8997], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6032, -0.8219, -3.0705], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6254, -0.7801, -1.2131], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2176, -2.5339, -0.8611], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6718, -1.1192, -0.9022], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8016, -0.9711, -0.7750], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4351, -2.7426, -0.6128], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0968, -0.8737, -1.1239], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7195, -0.7519, -1.1236], grad_fn=<MulBackward0>)\n",
      "tensor([-1.4421, -0.6147, -1.1374], grad_fn=<MulBackward0>)\n",
      "Step [300]: 1.111331582069397\n",
      "tensor([-2.3515, -0.4778, -2.1791], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0712, -2.5355, -1.4603], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8785, -0.8925, -0.6892], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5414, -0.9116, -0.7373], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7925, -0.8559, -2.8388], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7025, -1.0414, -0.8525], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0506, -0.8309, -1.0520], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7639, -4.2421, -0.8231], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6186, -0.6660, -0.7354], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7567, -3.2414, -2.7404], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5143, -0.8097, -0.6570], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0231, -1.1328, -0.7052], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7447, -0.7601, -1.1236], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5272, -0.5807, -3.3033], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1544, -0.8859, -1.1199], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7235, -1.1735, -0.8948], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0235, -0.9813, -0.9266], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9858, -0.8042, -1.5330], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7976, -0.4953, -1.1766], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8605, -0.5950, -0.9115], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2273, -0.6835, -1.3762], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6998, -1.1100, -1.5355], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9053, -0.5968, -1.2002], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9004, -1.0430, -2.7487], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5191, -1.1770, -1.0752], grad_fn=<MulBackward0>)\n",
      "Step [325]: 0.9704310894012451\n",
      "tensor([-1.3004, -1.0206, -1.1475], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1482, -0.8771, -1.3469], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6556, -0.6581, -0.6272], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6440, -0.7032, -1.1155], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8053, -0.6740, -1.5039], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6994, -0.5676, -0.6546], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5798, -0.7508, -0.9501], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9617, -0.6300, -2.2403], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7381, -0.8573, -1.1000], grad_fn=<MulBackward0>)\n",
      "tensor([-2.2996, -0.7194, -0.4785], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1870, -1.0413, -2.4864], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8543, -0.8788, -4.0497], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7799, -2.9048, -1.3271], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5905, -0.9651, -2.5584], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6223, -2.6212, -1.1845], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4169, -2.5759, -0.5551], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6584, -2.4903, -1.2502], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4120, -2.5458, -0.9371], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8179, -0.6779, -1.3660], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7259, -1.1373, -2.2557], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6386, -1.0088, -2.7440], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6506, -1.0196, -0.7796], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3657, -2.5957, -2.5840], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4095, -2.4629, -1.4198], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7205, -0.7076, -1.0083], grad_fn=<MulBackward0>)\n",
      "Step [350]: 1.525536298751831\n",
      "tensor([-0.7710, -0.9236, -1.0032], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5453, -0.7444, -0.7924], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9874, -0.8418, -2.3755], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6239, -1.2051, -2.3910], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8031, -0.6293, -1.1253], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6695, -0.7515, -0.9688], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8079, -0.7955, -4.1489], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7649, -0.8313, -0.6152], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5780, -0.7025, -1.4423], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4065, -2.4275, -0.6526], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1382, -1.2104, -0.7107], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5148, -0.7966, -1.4637], grad_fn=<MulBackward0>)\n",
      "tensor([-0.3421, -0.8315, -0.7798], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5764, -0.9744, -0.9530], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6211, -0.5438, -0.8868], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6826, -0.6656, -1.2340], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5730, -0.7290, -0.6505], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6182, -0.7332, -0.7583], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7426, -2.5176, -1.0063], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7168, -2.4929, -1.2843], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6134, -0.7610, -0.7509], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6337, -2.4722, -0.8074], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6132, -1.3073, -0.7699], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7864, -2.3974, -2.3972], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5556, -1.0069, -2.4815], grad_fn=<MulBackward0>)\n",
      "Step [375]: 1.3947786092758179\n",
      "tensor([-1.1434, -0.5696, -1.4948], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7489, -0.9227, -0.8817], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0009, -2.5355, -0.9208], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1060, -2.6697, -0.6937], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7041, -0.6092, -4.2552], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5913, -0.9494, -1.5513], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6639, -2.5855, -0.7074], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8133, -0.7881, -1.0610], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7765, -0.7510, -0.7172], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8111, -1.2011, -1.0324], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8300, -1.0995, -0.9850], grad_fn=<MulBackward0>)\n",
      "tensor([-2.2648, -0.7422, -0.8127], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6947, -0.9160, -0.9869], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4983, -2.3297, -2.7203], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6630, -0.7491, -1.0324], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8099, -0.7739, -1.0635], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5552, -0.8769, -1.3925], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4795, -0.4427, -1.1779], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6792, -0.7996, -1.3551], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5453, -0.7590, -0.8751], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7848, -0.8732, -1.1744], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8980, -2.5588, -4.2112], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4130, -0.6076, -1.3294], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9761, -0.7477, -1.3030], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7580, -0.8819, -1.1034], grad_fn=<MulBackward0>)\n",
      "Step [400]: 0.9612497091293335\n",
      "tensor([-0.3052, -0.7922, -1.1012], grad_fn=<MulBackward0>)\n",
      "tensor([-0.3865, -2.4935, -0.8990], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6190, -0.8397, -2.2209], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6166, -0.6365, -1.4091], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5592, -0.6283, -1.4258], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0963, -0.6843, -3.1094], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7994, -0.6344, -0.8438], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4318, -1.2651, -1.1748], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8508, -0.9687, -1.3615], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7110, -0.7602, -1.0954], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6567, -0.5925, -1.2138], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0759, -0.8699, -2.8113], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1583, -0.8496, -0.9788], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7579, -0.9042, -0.7782], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7746, -1.2185, -0.7719], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6714, -0.7734, -0.7261], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8364, -0.5028, -1.0228], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1962, -0.9481, -0.8221], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5722, -2.4830, -0.9372], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1827, -0.9784, -1.2835], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6699, -1.2333, -1.1949], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6961, -0.7629, -2.3709], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3641, -0.7428, -0.7284], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8293, -0.5541, -2.5547], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4319, -0.7155, -2.7549], grad_fn=<MulBackward0>)\n",
      "Step [425]: 1.3476626873016357\n",
      "tensor([-0.6105, -0.7865, -0.6476], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0087, -0.7328, -2.6826], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5666, -0.8734, -0.7902], grad_fn=<MulBackward0>)\n",
      "tensor([-2.8874, -2.3826, -0.9374], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9562, -0.7066, -0.8748], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9048, -2.4067, -4.0936], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7100, -0.6753, -0.9446], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9846, -2.4052, -1.3309], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0813, -1.2457, -0.5185], grad_fn=<MulBackward0>)\n",
      "tensor([-2.2815, -0.6582, -1.1800], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8998, -0.3807, -2.6610], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9947, -0.3923, -1.1370], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5724, -0.5610, -1.2009], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8320, -0.7966, -1.2443], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7373, -0.6417, -0.5922], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7942, -0.5562, -0.6951], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5024, -0.5945, -1.0706], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9951, -2.5697, -0.5957], grad_fn=<MulBackward0>)\n",
      "tensor([-0.3319, -4.3960, -0.9358], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2894, -2.5314, -0.7254], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8424, -1.6815, -1.0449], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6178, -0.7586, -0.6417], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5583, -4.2009, -0.7133], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9802, -0.9484, -0.9305], grad_fn=<MulBackward0>)\n",
      "tensor([-0.8850, -1.1238, -2.6184], grad_fn=<MulBackward0>)\n",
      "Step [450]: 1.5893564224243164\n",
      "tensor([-0.7729, -0.8547, -1.2470], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6754, -0.8868, -0.6651], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6597, -0.4083, -2.7411], grad_fn=<MulBackward0>)\n",
      "tensor([-0.3454, -2.4457, -0.6819], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7410, -0.7459, -0.8711], grad_fn=<MulBackward0>)\n",
      "tensor([-1.0027, -0.6140, -1.0181], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7727, -1.0634, -0.7863], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7898, -0.4822, -1.1162], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4070, -1.0801, -1.3755], grad_fn=<MulBackward0>)\n",
      "tensor([-2.6287, -0.9408, -0.7606], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1947, -0.9641, -1.2732], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7945, -0.8241, -0.9168], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5093, -0.7258, -0.8286], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5454, -2.3825, -1.1604], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6080, -0.5238, -0.7628], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6124, -0.8365, -0.7790], grad_fn=<MulBackward0>)\n",
      "tensor([-4.2459, -0.7301, -0.8235], grad_fn=<MulBackward0>)\n",
      "tensor([-2.3353, -0.6822, -0.5727], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5940, -0.6500, -0.6355], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6872, -3.3323, -2.4582], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1153, -2.2315, -2.7216], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4577, -2.3592, -1.1769], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4064, -0.7833, -0.8660], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7586, -0.9603, -2.3311], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7369, -0.5298, -0.9677], grad_fn=<MulBackward0>)\n",
      "Step [475]: 0.7917879819869995\n",
      "tensor([-0.5714, -0.4361, -2.1742], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5238, -0.5867, -4.0016], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5222, -2.4554, -2.5279], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4766, -0.6362, -0.8724], grad_fn=<MulBackward0>)\n",
      "tensor([-2.7824, -0.7784, -1.0422], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6842, -0.7306, -0.9606], grad_fn=<MulBackward0>)\n",
      "tensor([-0.4597, -0.5891, -1.1012], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9595, -1.0623, -0.9046], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7921, -0.7202, -1.1178], grad_fn=<MulBackward0>)\n",
      "tensor([-1.2208, -1.0742, -0.6134], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5430, -0.7300, -0.8142], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9969, -1.0981, -1.2569], grad_fn=<MulBackward0>)\n",
      "tensor([-0.9659, -0.7289, -0.5138], grad_fn=<MulBackward0>)\n",
      "tensor([-1.3129, -1.0658, -1.2209], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5876, -0.5390, -2.5256], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6346, -2.9161, -0.9266], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6572, -0.9498, -0.8693], grad_fn=<MulBackward0>)\n",
      "tensor([-2.4895, -0.6915, -1.0329], grad_fn=<MulBackward0>)\n",
      "tensor([-1.1389, -0.9389, -0.5740], grad_fn=<MulBackward0>)\n",
      "tensor([-2.5830, -2.6260, -0.7701], grad_fn=<MulBackward0>)\n",
      "tensor([-0.6554, -0.5939, -2.1206], grad_fn=<MulBackward0>)\n",
      "tensor([-0.5556, -2.6599, -0.8156], grad_fn=<MulBackward0>)\n",
      "tensor([-0.7168, -0.5849, -2.3468], grad_fn=<MulBackward0>)\n",
      "tensor([-1.5287, -2.3122, -0.5671], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    pred_proba = nvsm(query, document)\n",
    "    print(pred_proba)\n",
    "    loss = loss_function(nvsm, pred_proba, lamb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 25 == 0:\n",
    "        print(f'Step [{i}]: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
